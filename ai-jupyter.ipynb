{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Provinsi  Tahun   Produksi  Luas Panen  Curah hujan  Kelembapan  \\\n",
      "0     Aceh   1993  1329536.0    323589.0       1627.0       82.00   \n",
      "1     Aceh   1994  1299699.0    329041.0       1521.0       82.12   \n",
      "2     Aceh   1995  1382905.0    339253.0       1476.0       82.72   \n",
      "3     Aceh   1996  1419128.0    348223.0       1557.0       83.00   \n",
      "4     Aceh   1997  1368074.0    337561.0       1339.0       82.46   \n",
      "\n",
      "   Suhu rata-rata  \n",
      "0           26.06  \n",
      "1           26.92  \n",
      "2           26.27  \n",
      "3           26.08  \n",
      "4           26.31  \n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data_url = \"https://raw.githubusercontent.com/ajisakarsyi/ai-project/refs/heads/main/ai-dataset/Data_Tanaman_Padi_Sumatera_version_1.csv\"\n",
    "data = pd.read_csv(data_url)\n",
    "print(data.head())\n",
    "\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat cluster\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "data['Produksi_Cluster'] = kmeans.fit_predict(data[['Produksi']])\n",
    "\n",
    "# label cluster\n",
    "cluster_centers = kmeans.cluster_centers_.flatten()\n",
    "sorted_centroids = np.sort(cluster_centers)\n",
    "cluster_ranges = {\n",
    "    \"Low Production\": sorted_centroids[0],\n",
    "    \"Moderate Production\": sorted_centroids[1],\n",
    "    \"High Production\": sorted_centroids[2],\n",
    "    \"Very High Production\": sorted_centroids[3]\n",
    "}\n",
    "\n",
    "# map cluster\n",
    "def get_cluster_label(value):\n",
    "    if value <= sorted_centroids[0]:\n",
    "        return \"Low Production\"\n",
    "    elif value <= sorted_centroids[1]:\n",
    "        return \"Moderate Production\"\n",
    "    elif value <= sorted_centroids[2]:\n",
    "        return \"High Production\"\n",
    "    else:\n",
    "        return \"Very High Production\"\n",
    "\n",
    "# split data x input dan y target\n",
    "X = data[['Luas Panen', 'Curah hujan', 'Kelembapan', 'Suhu rata-rata']]\n",
    "y = data['Produksi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalisasi\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ajisaka\\Downloads\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2), \n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2), \n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4079051866112.0000 - mae: 1657553.7500 - val_loss: 3087897722880.0000 - val_mae: 1484509.6250\n",
      "Epoch 2/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4670995038208.0000 - mae: 1792382.1250 - val_loss: 3087896936448.0000 - val_mae: 1484509.5000\n",
      "Epoch 3/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4768742768640.0000 - mae: 1762885.2500 - val_loss: 3087895363584.0000 - val_mae: 1484509.0000\n",
      "Epoch 4/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4813786447872.0000 - mae: 1802923.5000 - val_loss: 3087891431424.0000 - val_mae: 1484507.7500\n",
      "Epoch 5/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4288672956416.0000 - mae: 1694811.6250 - val_loss: 3087881732096.0000 - val_mae: 1484504.3750\n",
      "Epoch 6/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4395217190912.0000 - mae: 1719506.0000 - val_loss: 3087857090560.0000 - val_mae: 1484496.7500\n",
      "Epoch 7/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4469556772864.0000 - mae: 1733975.0000 - val_loss: 3087803088896.0000 - val_mae: 1484479.8750\n",
      "Epoch 8/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4305721753600.0000 - mae: 1705634.2500 - val_loss: 3087690104832.0000 - val_mae: 1484445.1250\n",
      "Epoch 9/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3810683518976.0000 - mae: 1581818.7500 - val_loss: 3087467544576.0000 - val_mae: 1484377.8750\n",
      "Epoch 10/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4666598359040.0000 - mae: 1783551.1250 - val_loss: 3087066202112.0000 - val_mae: 1484259.1250\n",
      "Epoch 11/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5090341552128.0000 - mae: 1903794.8750 - val_loss: 3086370209792.0000 - val_mae: 1484055.2500\n",
      "Epoch 12/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4388523868160.0000 - mae: 1731801.2500 - val_loss: 3085271826432.0000 - val_mae: 1483736.3750\n",
      "Epoch 13/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4558638022656.0000 - mae: 1719120.2500 - val_loss: 3083510218752.0000 - val_mae: 1483229.8750\n",
      "Epoch 14/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4388539596800.0000 - mae: 1713948.2500 - val_loss: 3080758493184.0000 - val_mae: 1482449.6250\n",
      "Epoch 15/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4064049627136.0000 - mae: 1655659.1250 - val_loss: 3076788846592.0000 - val_mae: 1481330.6250\n",
      "Epoch 16/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4329201729536.0000 - mae: 1740831.6250 - val_loss: 3071009619968.0000 - val_mae: 1479718.0000\n",
      "Epoch 17/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4648001339392.0000 - mae: 1766509.8750 - val_loss: 3063015014400.0000 - val_mae: 1477494.6250\n",
      "Epoch 18/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4851587612672.0000 - mae: 1841910.1250 - val_loss: 3051812290560.0000 - val_mae: 1474412.1250\n",
      "Epoch 19/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4238433583104.0000 - mae: 1675918.5000 - val_loss: 3037651533824.0000 - val_mae: 1470502.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4712380235776.0000 - mae: 1784016.7500 - val_loss: 3018520002560.0000 - val_mae: 1465242.2500\n",
      "Epoch 21/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4151804428288.0000 - mae: 1679668.3750 - val_loss: 2993980964864.0000 - val_mae: 1458479.5000\n",
      "Epoch 22/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4233272229888.0000 - mae: 1667052.5000 - val_loss: 2962779275264.0000 - val_mae: 1449895.7500\n",
      "Epoch 23/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4145885216768.0000 - mae: 1668558.1250 - val_loss: 2922613833728.0000 - val_mae: 1438959.6250\n",
      "Epoch 24/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3750288162816.0000 - mae: 1587966.1250 - val_loss: 2873447940096.0000 - val_mae: 1425980.1250\n",
      "Epoch 25/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4052940226560.0000 - mae: 1623209.5000 - val_loss: 2814961516544.0000 - val_mae: 1410373.6250\n",
      "Epoch 26/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3903420366848.0000 - mae: 1604546.1250 - val_loss: 2745765199872.0000 - val_mae: 1391764.7500\n",
      "Epoch 27/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4003393175552.0000 - mae: 1639366.3750 - val_loss: 2665531572224.0000 - val_mae: 1369866.0000\n",
      "Epoch 28/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4040589312000.0000 - mae: 1642081.3750 - val_loss: 2569124970496.0000 - val_mae: 1343219.8750\n",
      "Epoch 29/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3605479292928.0000 - mae: 1504832.8750 - val_loss: 2459775533056.0000 - val_mae: 1312393.1250\n",
      "Epoch 30/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3874902245376.0000 - mae: 1593305.2500 - val_loss: 2332659023872.0000 - val_mae: 1275608.6250\n",
      "Epoch 31/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3446109372416.0000 - mae: 1481606.0000 - val_loss: 2198379036672.0000 - val_mae: 1235550.8750\n",
      "Epoch 32/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3774292426752.0000 - mae: 1579712.7500 - val_loss: 2043688779776.0000 - val_mae: 1188016.3750\n",
      "Epoch 33/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2817827012608.0000 - mae: 1365739.3750 - val_loss: 1880503353344.0000 - val_mae: 1135269.8750\n",
      "Epoch 34/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2998594961408.0000 - mae: 1373157.2500 - val_loss: 1701989318656.0000 - val_mae: 1076819.2500\n",
      "Epoch 35/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2366454104064.0000 - mae: 1236828.5000 - val_loss: 1522535890944.0000 - val_mae: 1014798.8750\n",
      "Epoch 36/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2422119858176.0000 - mae: 1234264.2500 - val_loss: 1333229256704.0000 - val_mae: 945515.3125\n",
      "Epoch 37/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2142948556800.0000 - mae: 1137013.1250 - val_loss: 1151201181696.0000 - val_mae: 874198.5000\n",
      "Epoch 38/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1782933880832.0000 - mae: 1035409.8125 - val_loss: 984076058624.0000 - val_mae: 806834.8750\n",
      "Epoch 39/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1615427534848.0000 - mae: 981390.7500 - val_loss: 816018227200.0000 - val_mae: 734504.8125\n",
      "Epoch 40/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1110272114688.0000 - mae: 825250.5000 - val_loss: 666723942400.0000 - val_mae: 664324.3750\n",
      "Epoch 41/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 958536679424.0000 - mae: 732908.1875 - val_loss: 541785128960.0000 - val_mae: 600783.4375\n",
      "Epoch 42/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 854026420224.0000 - mae: 678046.3750 - val_loss: 429612367872.0000 - val_mae: 531883.9375\n",
      "Epoch 43/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 805149278208.0000 - mae: 616857.9375 - val_loss: 351565512704.0000 - val_mae: 475050.7500\n",
      "Epoch 44/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 621069139968.0000 - mae: 564313.7500 - val_loss: 292971053056.0000 - val_mae: 428575.6562\n",
      "Epoch 45/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 551160119296.0000 - mae: 500827.8750 - val_loss: 253728784384.0000 - val_mae: 389084.8750\n",
      "Epoch 46/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 443325710336.0000 - mae: 440103.3750 - val_loss: 225760886784.0000 - val_mae: 352090.1875\n",
      "Epoch 47/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 462996865024.0000 - mae: 436270.2812 - val_loss: 206081097728.0000 - val_mae: 321892.9375\n",
      "Epoch 48/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 377908756480.0000 - mae: 376465.6250 - val_loss: 192989347840.0000 - val_mae: 306117.4375\n",
      "Epoch 49/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 446386143232.0000 - mae: 378249.2500 - val_loss: 184323342336.0000 - val_mae: 298383.5000\n",
      "Epoch 50/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 386032336896.0000 - mae: 392769.7500 - val_loss: 177241964544.0000 - val_mae: 294693.9062\n",
      "Epoch 51/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 397518209024.0000 - mae: 384667.7188 - val_loss: 171415945216.0000 - val_mae: 292719.0000\n",
      "Epoch 52/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 248623087616.0000 - mae: 318252.6250 - val_loss: 166605111296.0000 - val_mae: 291215.1562\n",
      "Epoch 53/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 340714061824.0000 - mae: 362811.9688 - val_loss: 162960834560.0000 - val_mae: 290964.5625\n",
      "Epoch 54/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 390277201920.0000 - mae: 422242.7188 - val_loss: 157185556480.0000 - val_mae: 288911.4375\n",
      "Epoch 55/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 331965759488.0000 - mae: 342645.3750 - val_loss: 153615777792.0000 - val_mae: 287759.7812\n",
      "Epoch 56/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 338835537920.0000 - mae: 353933.3125 - val_loss: 149561556992.0000 - val_mae: 285885.8125\n",
      "Epoch 57/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 421161533440.0000 - mae: 369393.2188 - val_loss: 146827919360.0000 - val_mae: 285486.3438\n",
      "Epoch 58/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472224825344.0000 - mae: 399169.3125 - val_loss: 143958278144.0000 - val_mae: 284375.1250\n",
      "Epoch 59/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 315643527168.0000 - mae: 346330.8438 - val_loss: 141703954432.0000 - val_mae: 284408.0312\n",
      "Epoch 60/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 356512530432.0000 - mae: 352408.5312 - val_loss: 139579752448.0000 - val_mae: 284527.9062\n",
      "Epoch 61/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 350188240896.0000 - mae: 346064.6250 - val_loss: 138604593152.0000 - val_mae: 284080.9375\n",
      "Epoch 62/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 306610012160.0000 - mae: 332577.0000 - val_loss: 135988191232.0000 - val_mae: 281381.4375\n",
      "Epoch 63/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 240813670400.0000 - mae: 318964.1875 - val_loss: 135076519936.0000 - val_mae: 280352.5000\n",
      "Epoch 64/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 287402295296.0000 - mae: 353896.7188 - val_loss: 134148169728.0000 - val_mae: 280350.5625\n",
      "Epoch 65/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 340250853376.0000 - mae: 350343.9375 - val_loss: 133694939136.0000 - val_mae: 281137.1250\n",
      "Epoch 66/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 262140837888.0000 - mae: 323354.1875 - val_loss: 132316954624.0000 - val_mae: 280262.5000\n",
      "Epoch 67/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 439741710336.0000 - mae: 396537.9062 - val_loss: 130952912896.0000 - val_mae: 280223.6562\n",
      "Epoch 68/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 255587352576.0000 - mae: 324433.1875 - val_loss: 127461564416.0000 - val_mae: 277152.7500\n",
      "Epoch 69/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 422429491200.0000 - mae: 388933.5938 - val_loss: 128115949568.0000 - val_mae: 279406.8750\n",
      "Epoch 70/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 320139100160.0000 - mae: 349547.2500 - val_loss: 129932648448.0000 - val_mae: 281528.5625\n",
      "Epoch 71/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 231425310720.0000 - mae: 303287.7188 - val_loss: 129447501824.0000 - val_mae: 281325.7188\n",
      "Epoch 72/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 257823686656.0000 - mae: 313749.8750 - val_loss: 129142751232.0000 - val_mae: 281599.8438\n",
      "Epoch 73/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359635156992.0000 - mae: 377606.5938 - val_loss: 130840788992.0000 - val_mae: 283884.6875\n",
      "Epoch 74/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 364443697152.0000 - mae: 371266.7188 - val_loss: 127660892160.0000 - val_mae: 281069.2500\n",
      "Epoch 75/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 424632942592.0000 - mae: 384468.5312 - val_loss: 126203551744.0000 - val_mae: 279358.5625\n",
      "Epoch 76/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 279383572480.0000 - mae: 319576.2812 - val_loss: 124071936000.0000 - val_mae: 277443.2812\n",
      "Epoch 77/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 270508687360.0000 - mae: 329315.4375 - val_loss: 122626768896.0000 - val_mae: 276425.6562\n",
      "Epoch 78/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201488826368.0000 - mae: 289389.1562 - val_loss: 122109681664.0000 - val_mae: 276089.1875\n",
      "Epoch 79/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 254473650176.0000 - mae: 305633.0000 - val_loss: 122915880960.0000 - val_mae: 276525.7812\n",
      "Epoch 80/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 307337232384.0000 - mae: 349496.6250 - val_loss: 124144476160.0000 - val_mae: 277558.1875\n",
      "Epoch 81/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 393952034816.0000 - mae: 370162.1562 - val_loss: 124648415232.0000 - val_mae: 277309.7188\n",
      "Epoch 82/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 363225874432.0000 - mae: 369006.2188 - val_loss: 123173601280.0000 - val_mae: 275777.5312\n",
      "Epoch 83/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 272526704640.0000 - mae: 316764.7812 - val_loss: 123595046912.0000 - val_mae: 276315.5312\n",
      "Epoch 84/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 327907344384.0000 - mae: 344239.1562 - val_loss: 123110744064.0000 - val_mae: 275799.4062\n",
      "Epoch 85/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337638850560.0000 - mae: 353003.1250 - val_loss: 121516400640.0000 - val_mae: 273758.0938\n",
      "Epoch 86/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 276751351808.0000 - mae: 343005.5938 - val_loss: 118889308160.0000 - val_mae: 270944.2500\n",
      "Epoch 87/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 322736848896.0000 - mae: 351218.0625 - val_loss: 116658446336.0000 - val_mae: 268346.0312\n",
      "Epoch 88/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 321610186752.0000 - mae: 316893.0312 - val_loss: 116205666304.0000 - val_mae: 267869.7812\n",
      "Epoch 89/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337178165248.0000 - mae: 328759.1562 - val_loss: 116734124032.0000 - val_mae: 268067.3750\n",
      "Epoch 90/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 283631026176.0000 - mae: 326839.2188 - val_loss: 118171648000.0000 - val_mae: 269486.8438\n",
      "Epoch 91/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 306040537088.0000 - mae: 336933.0000 - val_loss: 120518418432.0000 - val_mae: 271138.6250\n",
      "Epoch 92/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 347807350784.0000 - mae: 356160.0625 - val_loss: 118852149248.0000 - val_mae: 268910.5312\n",
      "Epoch 93/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 214777708544.0000 - mae: 288000.9688 - val_loss: 117330198528.0000 - val_mae: 266835.2812\n",
      "Epoch 94/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 290563129344.0000 - mae: 324438.2500 - val_loss: 116978163712.0000 - val_mae: 266418.4375\n",
      "Epoch 95/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 322696118272.0000 - mae: 325771.7188 - val_loss: 117786820608.0000 - val_mae: 266777.3438\n",
      "Epoch 96/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 367491907584.0000 - mae: 343050.6250 - val_loss: 119284678656.0000 - val_mae: 267840.1875\n",
      "Epoch 97/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 372038074368.0000 - mae: 374784.9688 - val_loss: 117394948096.0000 - val_mae: 265558.6562\n",
      "Epoch 98/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 328249475072.0000 - mae: 326815.0312 - val_loss: 115580731392.0000 - val_mae: 263261.6562\n",
      "Epoch 99/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337882808320.0000 - mae: 344303.4688 - val_loss: 115187941376.0000 - val_mae: 262654.8750\n",
      "Epoch 100/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 294551552000.0000 - mae: 318348.2812 - val_loss: 114626412544.0000 - val_mae: 262285.8750\n",
      "Epoch 101/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 233137094656.0000 - mae: 296301.3438 - val_loss: 113975787520.0000 - val_mae: 260923.8906\n",
      "Epoch 102/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 425315041280.0000 - mae: 371464.8750 - val_loss: 113956175872.0000 - val_mae: 260822.9375\n",
      "Epoch 103/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 294945030144.0000 - mae: 328728.4062 - val_loss: 113172717568.0000 - val_mae: 261003.4844\n",
      "Epoch 104/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 322494365696.0000 - mae: 356957.0625 - val_loss: 111660711936.0000 - val_mae: 260048.4375\n",
      "Epoch 105/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 402752864256.0000 - mae: 371990.4375 - val_loss: 112356016128.0000 - val_mae: 260658.9844\n",
      "Epoch 106/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 299131600896.0000 - mae: 331046.1250 - val_loss: 112968163328.0000 - val_mae: 260165.4062\n",
      "Epoch 107/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 347688501248.0000 - mae: 371462.8750 - val_loss: 113566736384.0000 - val_mae: 260255.7344\n",
      "Epoch 108/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 267844141056.0000 - mae: 306126.8438 - val_loss: 113903394816.0000 - val_mae: 260387.6250\n",
      "Epoch 109/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475959918592.0000 - mae: 385572.8750 - val_loss: 113913454592.0000 - val_mae: 259840.9844\n",
      "Epoch 110/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 255909838848.0000 - mae: 299515.0625 - val_loss: 111116517376.0000 - val_mae: 257171.4844\n",
      "Epoch 111/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 383643779072.0000 - mae: 361449.8125 - val_loss: 111463817216.0000 - val_mae: 258061.9531\n",
      "Epoch 112/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 271544926208.0000 - mae: 311756.7188 - val_loss: 110965972992.0000 - val_mae: 257509.6406\n",
      "Epoch 113/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 297047293952.0000 - mae: 336962.2188 - val_loss: 110843224064.0000 - val_mae: 257195.6875\n",
      "Epoch 114/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 300078268416.0000 - mae: 324692.9688 - val_loss: 112059170816.0000 - val_mae: 257930.4062\n",
      "Epoch 115/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 257970274304.0000 - mae: 304522.5625 - val_loss: 111103033344.0000 - val_mae: 257189.1719\n",
      "Epoch 116/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 284050817024.0000 - mae: 338449.0625 - val_loss: 109461618688.0000 - val_mae: 256043.6719\n",
      "Epoch 117/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 460218302464.0000 - mae: 392275.5000 - val_loss: 112885276672.0000 - val_mae: 259160.3594\n",
      "Epoch 118/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337691312128.0000 - mae: 348514.1250 - val_loss: 110471921664.0000 - val_mae: 257335.7500\n",
      "Epoch 119/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 346689601536.0000 - mae: 330402.0000 - val_loss: 110470021120.0000 - val_mae: 256926.3125\n",
      "Epoch 120/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 402103762944.0000 - mae: 374904.3438 - val_loss: 110009581568.0000 - val_mae: 256573.3281\n",
      "Epoch 121/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 407323344896.0000 - mae: 369465.0938 - val_loss: 111104868352.0000 - val_mae: 256948.7500\n",
      "Epoch 122/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 308677410816.0000 - mae: 336191.3438 - val_loss: 111440633856.0000 - val_mae: 256266.1719\n",
      "Epoch 123/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 201279586304.0000 - mae: 282347.7812 - val_loss: 113223467008.0000 - val_mae: 257176.3281\n",
      "Epoch 124/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359395098624.0000 - mae: 373908.7500 - val_loss: 114631811072.0000 - val_mae: 258768.7188\n",
      "Epoch 125/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 288309116928.0000 - mae: 336406.0625 - val_loss: 111662669824.0000 - val_mae: 255794.5938\n",
      "Epoch 126/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337602183168.0000 - mae: 341758.8750 - val_loss: 111388540928.0000 - val_mae: 255549.3594\n",
      "Epoch 127/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 348261679104.0000 - mae: 338214.1250 - val_loss: 108136849408.0000 - val_mae: 253081.7500\n",
      "Epoch 128/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 253488939008.0000 - mae: 288038.9375 - val_loss: 106240057344.0000 - val_mae: 251436.2031\n",
      "Epoch 129/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 451225255936.0000 - mae: 368484.9375 - val_loss: 106940260352.0000 - val_mae: 251974.2812\n",
      "Epoch 130/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 285461512192.0000 - mae: 321961.7500 - val_loss: 107084062720.0000 - val_mae: 251700.7969\n",
      "Epoch 131/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 380011872256.0000 - mae: 346093.7188 - val_loss: 107201699840.0000 - val_mae: 251809.4844\n",
      "Epoch 132/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 312958255104.0000 - mae: 315407.4375 - val_loss: 104581939200.0000 - val_mae: 249110.5781\n",
      "Epoch 133/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 320383483904.0000 - mae: 345187.6250 - val_loss: 105671548928.0000 - val_mae: 250130.5156\n",
      "Epoch 134/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 334866841600.0000 - mae: 324308.3438 - val_loss: 107621924864.0000 - val_mae: 251748.6406\n",
      "Epoch 135/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 243765067776.0000 - mae: 297832.6875 - val_loss: 107219877888.0000 - val_mae: 250856.9375\n",
      "Epoch 136/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241296424960.0000 - mae: 293773.4688 - val_loss: 107200552960.0000 - val_mae: 251149.8594\n",
      "Epoch 137/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 281324584960.0000 - mae: 318837.5312 - val_loss: 111584575488.0000 - val_mae: 254897.7812\n",
      "Epoch 138/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 304079011840.0000 - mae: 327522.0000 - val_loss: 113381703680.0000 - val_mae: 256391.2812\n",
      "Epoch 139/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 394914856960.0000 - mae: 355659.5000 - val_loss: 112703397888.0000 - val_mae: 255486.1562\n",
      "Epoch 140/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 423714684928.0000 - mae: 359441.9375 - val_loss: 109685858304.0000 - val_mae: 252426.7969\n",
      "Epoch 141/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 189465231360.0000 - mae: 267864.9062 - val_loss: 108909764608.0000 - val_mae: 250844.6875\n",
      "Epoch 142/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 271642918912.0000 - mae: 307920.0625 - val_loss: 108600483840.0000 - val_mae: 249820.1562\n",
      "Epoch 143/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 398645100544.0000 - mae: 360785.2500 - val_loss: 108328255488.0000 - val_mae: 249021.1719\n",
      "Epoch 144/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173416808448.0000 - mae: 258022.3281 - val_loss: 106151731200.0000 - val_mae: 245630.7969\n",
      "Epoch 145/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 238599143424.0000 - mae: 300065.8438 - val_loss: 106215751680.0000 - val_mae: 245576.3281\n",
      "Epoch 146/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 315081555968.0000 - mae: 333884.5000 - val_loss: 105993822208.0000 - val_mae: 245176.0938\n",
      "Epoch 147/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 294758481920.0000 - mae: 302060.5625 - val_loss: 107842617344.0000 - val_mae: 246520.6250\n",
      "Epoch 148/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475056013312.0000 - mae: 405017.6250 - val_loss: 108392054784.0000 - val_mae: 247535.5625\n",
      "Epoch 149/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 376134762496.0000 - mae: 352922.5938 - val_loss: 112635035648.0000 - val_mae: 252275.8281\n",
      "Epoch 150/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 292920000512.0000 - mae: 311635.5000 - val_loss: 111669182464.0000 - val_mae: 250898.2656\n",
      "Epoch 151/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 275029721088.0000 - mae: 333801.2188 - val_loss: 112486129664.0000 - val_mae: 251464.5312\n",
      "Epoch 152/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 262813745152.0000 - mae: 306735.0938 - val_loss: 111108571136.0000 - val_mae: 249587.5156\n",
      "Epoch 153/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 288053493760.0000 - mae: 339431.9375 - val_loss: 108109815808.0000 - val_mae: 245719.8906\n",
      "Epoch 154/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 312656822272.0000 - mae: 312210.6250 - val_loss: 108414967808.0000 - val_mae: 246121.2031\n",
      "Epoch 155/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 293986664448.0000 - mae: 324735.8750 - val_loss: 110292975616.0000 - val_mae: 248078.0469\n",
      "Epoch 156/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 310313779200.0000 - mae: 326716.2812 - val_loss: 110876803072.0000 - val_mae: 248319.4219\n",
      "Epoch 157/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 258445983744.0000 - mae: 305814.4688 - val_loss: 109628727296.0000 - val_mae: 246368.7969\n",
      "Epoch 158/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 282104037376.0000 - mae: 331731.2812 - val_loss: 109415063552.0000 - val_mae: 245627.2812\n",
      "Epoch 159/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 392590852096.0000 - mae: 350712.1875 - val_loss: 110341685248.0000 - val_mae: 246357.5625\n",
      "Epoch 160/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 344244420608.0000 - mae: 347690.7812 - val_loss: 108438708224.0000 - val_mae: 243726.4219\n",
      "Epoch 161/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 265880977408.0000 - mae: 296418.9062 - val_loss: 107987165184.0000 - val_mae: 242955.5625\n",
      "Epoch 162/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 325151555584.0000 - mae: 331462.2500 - val_loss: 105878241280.0000 - val_mae: 240254.5625\n",
      "Epoch 163/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 296089485312.0000 - mae: 303547.2812 - val_loss: 105989619712.0000 - val_mae: 240304.9062\n",
      "Epoch 164/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 229854527488.0000 - mae: 292541.7500 - val_loss: 108586090496.0000 - val_mae: 242900.0000\n",
      "Epoch 165/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 287303401472.0000 - mae: 313996.0938 - val_loss: 110472560640.0000 - val_mae: 245139.5938\n",
      "Epoch 166/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184634064896.0000 - mae: 275812.3125 - val_loss: 111198756864.0000 - val_mae: 246087.0000\n",
      "Epoch 167/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 345841827840.0000 - mae: 337947.6250 - val_loss: 115836936192.0000 - val_mae: 251452.3750\n",
      "Epoch 168/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 237120536576.0000 - mae: 300032.5938 - val_loss: 112679624704.0000 - val_mae: 247641.0625\n",
      "Epoch 169/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 303439609856.0000 - mae: 312721.0625 - val_loss: 109453115392.0000 - val_mae: 243474.3125\n",
      "Epoch 170/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 333065846784.0000 - mae: 349122.0000 - val_loss: 107792318464.0000 - val_mae: 241145.9062\n",
      "Epoch 171/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359666024448.0000 - mae: 339547.8438 - val_loss: 109110018048.0000 - val_mae: 242494.4062\n",
      "Epoch 172/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 332642287616.0000 - mae: 365013.0625 - val_loss: 107526275072.0000 - val_mae: 240656.4062\n",
      "Epoch 173/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337225023488.0000 - mae: 343941.8125 - val_loss: 106665590784.0000 - val_mae: 239829.8594\n",
      "Epoch 174/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 465833066496.0000 - mae: 369083.3125 - val_loss: 107090182144.0000 - val_mae: 240440.0938\n",
      "Epoch 175/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 263594508288.0000 - mae: 307542.1875 - val_loss: 106024640512.0000 - val_mae: 239302.5781\n",
      "Epoch 176/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 369010442240.0000 - mae: 331061.8750 - val_loss: 106430636032.0000 - val_mae: 239673.5625\n",
      "Epoch 177/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 294052593664.0000 - mae: 340141.9062 - val_loss: 107589197824.0000 - val_mae: 241109.4219\n",
      "Epoch 178/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 370556043264.0000 - mae: 358960.8750 - val_loss: 107016732672.0000 - val_mae: 240351.9062\n",
      "Epoch 179/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 427860000768.0000 - mae: 390890.3438 - val_loss: 106298335232.0000 - val_mae: 239334.5625\n",
      "Epoch 180/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 267226939392.0000 - mae: 317845.6562 - val_loss: 102934020096.0000 - val_mae: 235395.9531\n",
      "Epoch 181/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 231090896896.0000 - mae: 309703.6562 - val_loss: 103178739712.0000 - val_mae: 235955.2031\n",
      "Epoch 182/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 263096041472.0000 - mae: 294308.6250 - val_loss: 105133817856.0000 - val_mae: 238339.8281\n",
      "Epoch 183/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 385765670912.0000 - mae: 366298.5625 - val_loss: 106276290560.0000 - val_mae: 240945.0469\n",
      "Epoch 184/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 434386632704.0000 - mae: 361079.0000 - val_loss: 105083232256.0000 - val_mae: 239278.5312\n",
      "Epoch 185/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 300538822656.0000 - mae: 318810.1562 - val_loss: 105181282304.0000 - val_mae: 239184.5312\n",
      "Epoch 186/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 334728658944.0000 - mae: 345528.1250 - val_loss: 105923649536.0000 - val_mae: 240016.0938\n",
      "Epoch 187/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 212022001664.0000 - mae: 297518.1250 - val_loss: 104338333696.0000 - val_mae: 237359.0469\n",
      "Epoch 188/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 291733438464.0000 - mae: 320304.6875 - val_loss: 107242938368.0000 - val_mae: 240912.5781\n",
      "Epoch 189/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 341434204160.0000 - mae: 336040.5938 - val_loss: 108254773248.0000 - val_mae: 241989.7812\n",
      "Epoch 190/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 272079831040.0000 - mae: 312482.7188 - val_loss: 105743736832.0000 - val_mae: 237861.9531\n",
      "Epoch 191/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 193598029824.0000 - mae: 269595.1250 - val_loss: 104092065792.0000 - val_mae: 234562.1719\n",
      "Epoch 192/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 216680677376.0000 - mae: 294283.6250 - val_loss: 103883448320.0000 - val_mae: 234192.9844\n",
      "Epoch 193/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 343364927488.0000 - mae: 351082.6250 - val_loss: 107792457728.0000 - val_mae: 239761.2031\n",
      "Epoch 194/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 348867821568.0000 - mae: 342823.7812 - val_loss: 108465152000.0000 - val_mae: 240492.7969\n",
      "Epoch 195/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 312244731904.0000 - mae: 314026.6562 - val_loss: 108736315392.0000 - val_mae: 240654.4219\n",
      "Epoch 196/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 239406678016.0000 - mae: 300855.7500 - val_loss: 104175222784.0000 - val_mae: 234878.3594\n",
      "Epoch 197/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 345751519232.0000 - mae: 340202.3750 - val_loss: 103327014912.0000 - val_mae: 234125.5625\n",
      "Epoch 198/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 423715307520.0000 - mae: 379241.0938 - val_loss: 104410996736.0000 - val_mae: 235247.2031\n",
      "Epoch 199/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 292074913792.0000 - mae: 323946.8125 - val_loss: 106174939136.0000 - val_mae: 236921.9531\n",
      "Epoch 200/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 283768061952.0000 - mae: 320205.5000 - val_loss: 106908418048.0000 - val_mae: 238156.7188\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi prediksi\n",
    "def predict_production(luas_panen, curah_hujan, kelembapan, suhu_rata_rata):\n",
    "    weather_features = np.array([[luas_panen, curah_hujan, kelembapan, suhu_rata_rata]])\n",
    "    weather_features = scaler.transform(weather_features)\n",
    "    prediction = model.predict(weather_features)[0][0]\n",
    "\n",
    "    cluster_category = get_cluster_label(prediction)\n",
    "\n",
    "    return prediction, cluster_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Predicted Production: 1997715.625\n",
      "Production Cluster: High Production\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ajisaka\\Downloads\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# contoh input\n",
    "luas_panen = 300000\n",
    "curah_hujan = 1600\n",
    "kelembapan = 90\n",
    "suhu_rata_rata = 20\n",
    "predicted_production, production_cluster = predict_production(luas_panen, curah_hujan, kelembapan, suhu_rata_rata)\n",
    "print(f\"Predicted Production: {predicted_production}\")\n",
    "print(f\"Production Cluster: {production_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('ai-model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
